./BIG-Bench-Hard/bbh
['./BIG-Bench-Hard/bbh/salient_translation_error_detection.json', './BIG-Bench-Hard/bbh/dyck_languages.json', './BIG-Bench-Hard/bbh/tracking_shuffled_objects_seven_objects.json', './BIG-Bench-Hard/bbh/tracking_shuffled_objects_five_objects.json', './BIG-Bench-Hard/bbh/object_counting.json', './BIG-Bench-Hard/bbh/web_of_lies.json', './BIG-Bench-Hard/bbh/logical_deduction_three_objects.json', './BIG-Bench-Hard/bbh/penguins_in_a_table.json', './BIG-Bench-Hard/bbh/disambiguation_qa.json', './BIG-Bench-Hard/bbh/temporal_sequences.json', './BIG-Bench-Hard/bbh/movie_recommendation.json', './BIG-Bench-Hard/bbh/boolean_expressions.json', './BIG-Bench-Hard/bbh/snarks.json', './BIG-Bench-Hard/bbh/navigate.json', './BIG-Bench-Hard/bbh/formal_fallacies.json', './BIG-Bench-Hard/bbh/date_understanding.json', './BIG-Bench-Hard/bbh/ruin_names.json', './BIG-Bench-Hard/bbh/multistep_arithmetic_two.json', './BIG-Bench-Hard/bbh/sports_understanding.json', './BIG-Bench-Hard/bbh/tracking_shuffled_objects_three_objects.json', './BIG-Bench-Hard/bbh/hyperbaton.json', './BIG-Bench-Hard/bbh/logical_deduction_five_objects.json', './BIG-Bench-Hard/bbh/geometric_shapes.json', './BIG-Bench-Hard/bbh/reasoning_about_colored_objects.json', './BIG-Bench-Hard/bbh/causal_judgement.json', './BIG-Bench-Hard/bbh/logical_deduction_seven_objects.json', './BIG-Bench-Hard/bbh/word_sorting.json']


Running tokenizer on train dataset:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 15/16 [00:05<00:00,  2.61ba/s]
/extra/ucinlp1/dylan/Exploring-Instruction-Tuning/train.py:66: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ü§ó Evaluate: https://huggingface.co/docs/evaluate
  acc_metric = datasets.load_metric("accuracy_metric.py")
***** Running Evaluation *****
  Num examples = 200
  Batch size = 12
/extra/ucinlp1/dylan/pytorch/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '














100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:29<00:00,  2.28s/it]
========
Example predictions and references
['AnaA) Joe  ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana', '(B) ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( (', 'CC) The the ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( C C The The The ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( (', '(09) 09 = ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( 09 09 09 09 09 09 09 09 09 09 ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( (', '(D) 04 to ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( Yesterday ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( (', '(A) line ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( (', 'It- yes yes yes yes yes yes yes yes yes yes yes yes no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It yes no no no no no no It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It', '(A) ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( (', 'RobB) Rob  ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob', '(B): ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( (']
['(C)', '(E)', '(C)', '(E)', '(C)', '(I)', 'yes', '(C)', '(B)', '(B)']
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:29<00:00,  2.28s/it]Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:32<00:00,  1.88s/it]
/home/dslack/.conda/envs/benchmark-description-learning/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 15014
  Num Epochs = 10
  Instantaneous batch size per device = 2
  Total train batch size (w. parallel, distributed & accumulation) = 96
  Gradient Accumulation steps = 8
  Total optimization steps = 1560
  Number of trainable parameters = 783150080
  0%|          | 0/1560 [00:00<?, ?it/s]/extra/ucinlp1/dylan/pytorch/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '























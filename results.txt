wandb: Currently logged in as: dslack. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /extra/ucinlp1/dylan/Exploring-Instruction-Tuning/wandb/run-20230422_000146-t34ihkxu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run test
wandb: ‚≠êÔ∏è View project at https://wandb.ai/dslack/Instruction%20Tuning%20Exploration
wandb: üöÄ View run at https://wandb.ai/dslack/Instruction%20Tuning%20Exploration/runs/t34ihkxu
./BIG-Bench-Hard/bbh
['./BIG-Bench-Hard/bbh/salient_translation_error_detection.json', './BIG-Bench-Hard/bbh/dyck_languages.json', './BIG-Bench-Hard/bbh/tracking_shuffled_objects_seven_objects.json', './BIG-Bench-Hard/bbh/tracking_shuffled_objects_five_objects.json', './BIG-Bench-Hard/bbh/object_counting.json', './BIG-Bench-Hard/bbh/web_of_lies.json', './BIG-Bench-Hard/bbh/logical_deduction_three_objects.json', './BIG-Bench-Hard/bbh/penguins_in_a_table.json', './BIG-Bench-Hard/bbh/disambiguation_qa.json', './BIG-Bench-Hard/bbh/temporal_sequences.json', './BIG-Bench-Hard/bbh/movie_recommendation.json', './BIG-Bench-Hard/bbh/boolean_expressions.json', './BIG-Bench-Hard/bbh/snarks.json', './BIG-Bench-Hard/bbh/navigate.json', './BIG-Bench-Hard/bbh/formal_fallacies.json', './BIG-Bench-Hard/bbh/date_understanding.json', './BIG-Bench-Hard/bbh/ruin_names.json', './BIG-Bench-Hard/bbh/multistep_arithmetic_two.json', './BIG-Bench-Hard/bbh/sports_understanding.json', './BIG-Bench-Hard/bbh/tracking_shuffled_objects_three_objects.json', './BIG-Bench-Hard/bbh/hyperbaton.json', './BIG-Bench-Hard/bbh/logical_deduction_five_objects.json', './BIG-Bench-Hard/bbh/geometric_shapes.json', './BIG-Bench-Hard/bbh/reasoning_about_colored_objects.json', './BIG-Bench-Hard/bbh/causal_judgement.json', './BIG-Bench-Hard/bbh/logical_deduction_seven_objects.json', './BIG-Bench-Hard/bbh/word_sorting.json']
./BIG-Bench-Hard/bbh
['./BIG-Bench-Hard/bbh/salient_translation_error_detection.json', './BIG-Bench-Hard/bbh/dyck_languages.json', './BIG-Bench-Hard/bbh/tracking_shuffled_objects_seven_objects.json', './BIG-Bench-Hard/bbh/tracking_shuffled_objects_five_objects.json', './BIG-Bench-Hard/bbh/object_counting.json', './BIG-Bench-Hard/bbh/web_of_lies.json', './BIG-Bench-Hard/bbh/logical_deduction_three_objects.json', './BIG-Bench-Hard/bbh/penguins_in_a_table.json', './BIG-Bench-Hard/bbh/disambiguation_qa.json', './BIG-Bench-Hard/bbh/temporal_sequences.json', './BIG-Bench-Hard/bbh/movie_recommendation.json', './BIG-Bench-Hard/bbh/boolean_expressions.json', './BIG-Bench-Hard/bbh/snarks.json', './BIG-Bench-Hard/bbh/navigate.json', './BIG-Bench-Hard/bbh/formal_fallacies.json', './BIG-Bench-Hard/bbh/date_understanding.json', './BIG-Bench-Hard/bbh/ruin_names.json', './BIG-Bench-Hard/bbh/multistep_arithmetic_two.json', './BIG-Bench-Hard/bbh/sports_understanding.json', './BIG-Bench-Hard/bbh/tracking_shuffled_objects_three_objects.json', './BIG-Bench-Hard/bbh/hyperbaton.json', './BIG-Bench-Hard/bbh/logical_deduction_five_objects.json', './BIG-Bench-Hard/bbh/geometric_shapes.json', './BIG-Bench-Hard/bbh/reasoning_about_colored_objects.json', './BIG-Bench-Hard/bbh/causal_judgement.json', './BIG-Bench-Hard/bbh/logical_deduction_seven_objects.json', './BIG-Bench-Hard/bbh/word_sorting.json']
Running tokenizer on train dataset:   0%|          | 0/16 [00:00<?, ?ba/s]Running tokenizer on train dataset:   6%|‚ñã         | 1/16 [00:00<00:07,  2.03ba/s]Running tokenizer on train dataset:  12%|‚ñà‚ñé        | 2/16 [00:00<00:06,  2.28ba/s]Running tokenizer on train dataset:  19%|‚ñà‚ñâ        | 3/16 [00:01<00:05,  2.45ba/s]Running tokenizer on train dataset:  25%|‚ñà‚ñà‚ñå       | 4/16 [00:01<00:04,  2.60ba/s]Running tokenizer on train dataset:  31%|‚ñà‚ñà‚ñà‚ñè      | 5/16 [00:02<00:04,  2.33ba/s]Running tokenizer on train dataset:  38%|‚ñà‚ñà‚ñà‚ñä      | 6/16 [00:02<00:04,  2.47ba/s]Running tokenizer on train dataset:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 7/16 [00:02<00:03,  2.61ba/s]Running tokenizer on train dataset:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 8/16 [00:03<00:02,  2.69ba/s]Running tokenizer on train dataset:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 9/16 [00:03<00:02,  2.71ba/s]Running tokenizer on train dataset:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 10/16 [00:03<00:02,  2.67ba/s]Running tokenizer on train dataset:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 11/16 [00:04<00:01,  2.70ba/s]Running tokenizer on train dataset:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 12/16 [00:04<00:01,  2.72ba/s]Running tokenizer on train dataset:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 13/16 [00:05<00:01,  2.71ba/s]Running tokenizer on train dataset:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 14/16 [00:05<00:00,  2.74ba/s]Running tokenizer on train dataset:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 15/16 [00:05<00:00,  2.77ba/s]Running tokenizer on train dataset:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 15/16 [00:05<00:00,  2.61ba/s]
Running tokenizer on test dataset #0:   0%|          | 0/1 [00:00<?, ?ba/s]
Running tokenizer on test dataset #1:   0%|          | 0/1 [00:00<?, ?ba/s][ARunning tokenizer on test dataset #0:   0%|          | 0/1 [00:00<?, ?ba/s]
Running tokenizer on test dataset #1:   0%|          | 0/1 [00:00<?, ?ba/s]


Running tokenizer on test dataset #2:   0%|          | 0/1 [00:00<?, ?ba/s][A[A


Running tokenizer on test dataset #3:   0%|          | 0/1 [00:00<?, ?ba/s][A[A[ARunning tokenizer on test dataset #2:   0%|          | 0/1 [00:00<?, ?ba/s]




Running tokenizer on test dataset #4:   0%|          | 0/1 [00:00<?, ?ba/s][A[A[A[ARunning tokenizer on test dataset #3:   0%|          | 0/1 [00:00<?, ?ba/s]
Running tokenizer on test dataset #4:   0%|          | 0/1 [00:00<?, ?ba/s]





Running tokenizer on test dataset #5:   0%|          | 0/1 [00:00<?, ?ba/s][A[A[A[A[A





Running tokenizer on test dataset #6:   0%|          | 0/1 [00:00<?, ?ba/s][A[A[A[A[A[ARunning tokenizer on test dataset #5:   0%|          | 0/1 [00:00<?, ?ba/s]







Running tokenizer on test dataset #7:   0%|          | 0/1 [00:00<?, ?ba/s][A[A[A[A[A[A[ARunning tokenizer on test dataset #6:   0%|          | 0/1 [00:00<?, ?ba/s]
Running tokenizer on test dataset #7:   0%|          | 0/1 [00:00<?, ?ba/s]
/extra/ucinlp1/dylan/Exploring-Instruction-Tuning/train.py:66: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ü§ó Evaluate: https://huggingface.co/docs/evaluate
  acc_metric = datasets.load_metric("accuracy_metric.py")
***** Running Evaluation *****
  Num examples = 200
  Batch size = 12
/extra/ucinlp1/dylan/pytorch/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/17 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 2/17 [00:00<00:06,  2.29it/s] 18%|‚ñà‚ñä        | 3/17 [00:02<00:12,  1.11it/s] 24%|‚ñà‚ñà‚ñé       | 4/17 [00:04<00:15,  1.20s/it] 29%|‚ñà‚ñà‚ñâ       | 5/17 [00:05<00:15,  1.33s/it] 35%|‚ñà‚ñà‚ñà‚ñå      | 6/17 [00:07<00:15,  1.40s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 7/17 [00:08<00:14,  1.50s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 8/17 [00:10<00:14,  1.56s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 9/17 [00:12<00:13,  1.64s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 10/17 [00:14<00:11,  1.69s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 11/17 [00:16<00:10,  1.78s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 12/17 [00:18<00:09,  1.85s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 13/17 [00:20<00:07,  1.90s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 14/17 [00:22<00:05,  1.99s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 15/17 [00:24<00:04,  2.04s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 16/17 [00:27<00:02,  2.15s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:29<00:00,  2.28s/it]========
Example predictions and references
['AnaA) Joe  ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana Ana', '(B) ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( (', 'CC) The the ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( C C The The The ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( (', '(09) 09 = ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( 09 09 09 09 09 09 09 09 09 09 ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( (', '(D) 04 to ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( Yesterday ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( (', '(A) line ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( (', 'It- yes yes yes yes yes yes yes yes yes yes yes yes no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It yes no no no no no no It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It It', '(A) ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( (', 'RobB) Rob  ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob Rob', '(B): ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( (']
['(C)', '(E)', '(C)', '(E)', '(C)', '(I)', 'yes', '(C)', '(B)', '(B)']
Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:32<00:00,  1.88s/it]
/home/dslack/.conda/envs/benchmark-description-learning/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 15014
  Num Epochs = 10
  Instantaneous batch size per device = 2
  Total train batch size (w. parallel, distributed & accumulation) = 96
  Gradient Accumulation steps = 8
  Total optimization steps = 1560
  Number of trainable parameters = 783150080
========
  0%|          | 0/1560 [00:00<?, ?it/s]/extra/ucinlp1/dylan/pytorch/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 1/1560 [00:15<6:51:40, 15.84s/it]  0%|          | 2/1560 [00:27<5:48:17, 13.41s/it]  0%|          | 3/1560 [00:39<5:30:03, 12.72s/it]  0%|          | 4/1560 [00:51<5:19:38, 12.33s/it]  0%|          | 5/1560 [01:02<5:14:21, 12.13s/it]  0%|          | 6/1560 [01:14<5:11:02, 12.01s/it]  0%|          | 7/1560 [01:26<5:09:09, 11.94s/it]  1%|          | 8/1560 [01:38<5:07:05, 11.87s/it]  1%|          | 9/1560 [01:50<5:06:25, 11.85s/it]  1%|          | 10/1560 [02:01<5:05:02, 11.81s/it]  1%|          | 11/1560 [02:13<5:05:21, 11.83s/it]  1%|          | 12/1560 [02:25<5:04:33, 11.80s/it]  1%|          | 13/1560 [02:37<5:04:31, 11.81s/it]  1%|          | 14/1560 [02:48<5:03:40, 11.79s/it]  1%|          | 15/1560 [03:00<5:04:06, 11.81s/it]  1%|          | 16/1560 [03:12<5:03:48, 11.81s/it]  1%|          | 17/1560 [03:24<5:03:41, 11.81s/it]  1%|          | 18/1560 [03:36<5:03:01, 11.79s/it]  1%|          | 19/1560 [03:47<5:03:02, 11.80s/it]  1%|‚ñè         | 20/1560 [03:59<5:02:31, 11.79s/it]  1%|‚ñè         | 21/1560 [04:11<5:02:30, 11.79s/it]  1%|‚ñè         | 22/1560 [04:23<5:02:14, 11.79s/it]  1%|‚ñè         | 23/1560 [04:35<5:02:10, 11.80s/it]slurmstepd: error: *** JOB 174050 ON ava-s4 CANCELLED AT 2023-04-22T00:08:22 ***
